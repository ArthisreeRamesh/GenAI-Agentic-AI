{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CSjJ80crzhuSQqdY6KIcJweAF09Topmn",
      "authorship_tag": "ABX9TyPp1IyUTLXYQduQt3HBOrwb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f07887e47d8427a952b3220c5932899": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_b5104e53fac24a4b812153765f21527a",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:07\u001b[0m\n    ğŸ¯ Evaluating test case #0        \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:07\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:07</span>\n    ğŸ¯ Evaluating test case #0        <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:07</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "b5104e53fac24a4b812153765f21527a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19eac8f4b4f04b63831af70a341ea7a2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_50aa3aadbc6542baaf36c4e6a8ba5292",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:03\u001b[0m\n    ğŸ¯ Evaluating test case #0        \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:03\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:03</span>\n    ğŸ¯ Evaluating test case #0        <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:03</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "50aa3aadbc6542baaf36c4e6a8ba5292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc0f3e64b864ffbaef08bc782c6a367": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ab6f0cfeeeb9452fa6e654a1aa3566a1",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:04\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:04</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "ab6f0cfeeeb9452fa6e654a1aa3566a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd11a9c03ed41b5b018936d6d4c3005": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2d95c9c5b0b6453a8c54c9a7c8f9c36f",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:04\u001b[0m\n    ğŸ¯ Evaluating test case #0        \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:04\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:04</span>\n    ğŸ¯ Evaluating test case #0        <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:04</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "2d95c9c5b0b6453a8c54c9a7c8f9c36f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492d8ed0e87841528f0a20c2d564c2e9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_606b44265e5f42298c63245f0b5d43b9",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:05\u001b[0m\n    ğŸ¯ Evaluating test case #0        \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:05\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:05</span>\n    ğŸ¯ Evaluating test case #0        <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:05</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "606b44265e5f42298c63245f0b5d43b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3bc76345f1b47d597d5399faeeb2246": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4b2c369eac0c4361be7f3dca1ae5d471",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:06\u001b[0m\n    ğŸ¯ Evaluating test case #0        \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:06\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:06</span>\n    ğŸ¯ Evaluating test case #0        <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:06</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "4b2c369eac0c4361be7f3dca1ae5d471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9faa3b5924664d6f92d5b810521bff22": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e48c59d320cc4f65b9d86bfb3e552b25",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:05\u001b[0m\n    ğŸ¯ Evaluating test case #0        \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:05\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:05</span>\n    ğŸ¯ Evaluating test case #0        <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:05</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "e48c59d320cc4f65b9d86bfb3e552b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthisreeRamesh/GenAI-Agentic-AI/blob/main/Aug3EndTevvaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFaxITFZcYm_",
        "outputId": "6a909aa9-4cae-450e-c6d2-70c52dde8fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.41)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.2 (from langchain-openai)\n",
            "  Downloading langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.41)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.0.2-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m471.2/471.2 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.4 langchain-openai-1.0.2\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.4)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.41)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-1.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting chromadb<2.0.0,>=1.0.20 (from langchain-chroma)\n",
            "  Downloading chromadb-1.3.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-chroma) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain-chroma) (2.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.11.10)\n",
            "Collecting pybase64>=1.4.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.25.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-chroma) (0.4.41)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-chroma) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.28.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.32.5)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-chroma) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-chroma) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.2.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.4.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.6.1)\n",
            "Downloading langchain_chroma-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading chromadb-1.3.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=b1609c8fb9b7ed1a46d07f411db33dd9f97495f2c42e51292779998960bbf64c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-chroma\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.3.4 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-chroma-1.0.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n",
            "Collecting ragas\n",
            "  Downloading ragas-0.3.8-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (2.0.2)\n",
            "Requirement already satisfied: datasets>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (4.0.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from ragas) (0.12.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (2.11.10)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ragas) (1.6.0)\n",
            "Collecting appdirs (from ragas)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting diskcache>=5.6.3 (from ragas)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from ragas) (0.20.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from ragas) (13.9.4)\n",
            "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (1.109.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ragas) (4.67.1)\n",
            "Collecting instructor (from ragas)\n",
            "  Downloading instructor-1.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.12/dist-packages (from ragas) (3.1.45)\n",
            "Requirement already satisfied: pillow>=10.4.0 in /usr/local/lib/python3.12/dist-packages (from ragas) (11.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from ragas) (3.5)\n",
            "Collecting scikit-network (from ragas)\n",
            "  Downloading scikit_network-0.33.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from ragas) (0.3.27)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (from ragas) (1.0.4)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (from ragas) (0.4.1)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (from ragas) (1.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (2.32.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=4.0.0->ragas) (6.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->ragas) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->ragas) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->ragas) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->ragas) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->ragas) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->ragas) (0.4.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython->ragas) (4.0.12)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from instructor->ragas) (3.13.2)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from instructor->ragas) (0.17.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from instructor->ragas) (3.1.6)\n",
            "Collecting openai>=1.0.0 (from ragas)\n",
            "  Downloading openai-2.7.2-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pre-commit>=4.3.0 (from instructor->ragas)\n",
            "  Downloading pre_commit-4.4.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from instructor->ragas) (8.5.0)\n",
            "Collecting ty>=0.0.1a23 (from instructor->ragas)\n",
            "  Downloading ty-0.0.1a26-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->ragas) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->ragas) (2.19.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer->ragas) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->ragas) (1.5.4)\n",
            "Collecting langchain-core (from ragas)\n",
            "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain->ragas)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain->ragas) (0.4.41)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain->ragas) (2.0.44)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->ragas) (1.33)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community (from ragas)\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community->ragas) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community->ragas) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->ragas) (0.4.3)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_openai (from ragas)\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->ragas) (2024.11.6)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.12/dist-packages (from scikit-network->ragas) (1.16.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.0.0->ragas) (3.11)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas) (0.9.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython->ragas) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->ragas) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->ragas) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->ragas) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->ragas) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->ragas) (0.25.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=4.0.0->ragas) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=4.0.0->ragas) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=4.0.0->ragas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=4.0.0->ragas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=4.0.0->ragas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=4.0.0->ragas) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas) (1.1.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas) (4.5.0)\n",
            "Downloading ragas-0.3.8-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading instructor-1.13.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.7.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_network-0.33.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
            "Downloading pre_commit-4.4.0-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ty-0.0.1a26-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distlib, appdirs, virtualenv, ty, nodeenv, identify, diskcache, cfgv, scikit-network, pre-commit, openai, langchain-core, instructor, langchain-text-splitters, langchain_openai, langchain-community, ragas\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.0.4\n",
            "    Uninstalling langchain-core-1.0.4:\n",
            "      Successfully uninstalled langchain-core-1.0.4\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 1.0.0\n",
            "    Uninstalling langchain-text-splitters-1.0.0:\n",
            "      Successfully uninstalled langchain-text-splitters-1.0.0\n",
            "  Attempting uninstall: langchain_openai\n",
            "    Found existing installation: langchain-openai 1.0.2\n",
            "    Uninstalling langchain-openai-1.0.2:\n",
            "      Successfully uninstalled langchain-openai-1.0.2\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.4.1\n",
            "    Uninstalling langchain-community-0.4.1:\n",
            "      Successfully uninstalled langchain-community-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-chroma 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.3.11 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 cfgv-3.4.0 diskcache-5.6.3 distlib-0.4.0 identify-2.6.15 instructor-1.13.0 langchain-community-0.3.31 langchain-core-0.3.79 langchain-text-splitters-0.3.11 langchain_openai-0.3.35 nodeenv-1.9.1 openai-2.7.2 pre-commit-4.4.0 ragas-0.3.8 scikit-network-0.33.3 ty-0.0.1a26 virtualenv-20.35.4\n",
            "Collecting deepeval\n",
            "  Downloading deepeval-3.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.13.2)\n",
            "Collecting anthropic (from deepeval)\n",
            "  Downloading anthropic-0.72.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting click<8.3.0,>=8.0.0 (from deepeval)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.49.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.76.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.6.0)\n",
            "Collecting ollama (from deepeval)\n",
            "  Downloading ollama-0.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.7.2)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.38.0)\n",
            "Collecting portalocker (from deepeval)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: posthog<6.0.0,>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (5.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.11.10)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.11.0)\n",
            "Collecting pyfiglet (from deepeval)\n",
            "  Downloading pyfiglet-1.0.4-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from deepeval) (8.4.2)\n",
            "Collecting pytest-asyncio (from deepeval)\n",
            "  Downloading pytest_asyncio-1.3.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pytest-repeat (from deepeval)\n",
            "  Downloading pytest_repeat-0.9.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pytest-rerunfailures<13.0,>=12.0 (from deepeval)\n",
            "  Downloading pytest_rerunfailures-12.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting pytest-xdist (from deepeval)\n",
            "  Downloading pytest_xdist-3.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.2.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.32.5)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.6.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (13.9.4)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.43.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from deepeval) (75.2.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.9.0)\n",
            "Requirement already satisfied: tenacity<=10.0.0,>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (8.5.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (4.67.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9 in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.20.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.45.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (0.28.1)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (4.15.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.38.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.59b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (0.4.2)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/dist-packages (from pytest-rerunfailures<13.0,>=12.0->deepeval) (25.0)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval) (2025.10.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.6.0->deepeval) (4.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.9->deepeval) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (1.22.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic->deepeval) (0.17.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic->deepeval) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic->deepeval) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->deepeval) (3.0.3)\n",
            "Collecting execnet>=2.1 (from pytest-xdist->deepeval)\n",
            "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->deepeval) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.6.1)\n",
            "Downloading deepeval-3.7.0-py3-none-any.whl (708 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m708.6/708.6 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_rerunfailures-12.0-py3-none-any.whl (12 kB)\n",
            "Downloading anthropic-0.72.0-py3-none-any.whl (357 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m357.5/357.5 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ollama-0.6.0-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading pyfiglet-1.0.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_asyncio-1.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading pytest_repeat-0.9.4-py3-none-any.whl (4.2 kB)\n",
            "Downloading pytest_xdist-3.8.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyfiglet, portalocker, execnet, click, pytest-xdist, pytest-rerunfailures, pytest-repeat, pytest-asyncio, ollama, anthropic, deepeval\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anthropic-0.72.0 click-8.2.1 deepeval-3.7.0 execnet-2.1.1 ollama-0.6.0 portalocker-3.2.0 pyfiglet-1.0.4 pytest-asyncio-1.3.0 pytest-repeat-0.9.4 pytest-rerunfailures-12.0 pytest-xdist-3.8.0\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (0.3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-chroma\n",
        "!pip install ragas\n",
        "!pip install deepeval\n",
        "!pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "OPEN_API_KEY=getpass(\"Enter api key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs3s3psBlMZK",
        "outputId": "4ca0793e-25f3-474f-be45-d1b56a7a200c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter api keyÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPEN_API_KEY"
      ],
      "metadata": {
        "id": "kSCY8G99lWI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddingmodel= OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
      ],
      "metadata": {
        "id": "21CwtqZAld9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is to download the data but we have it handy so directly uploading\n",
        "#!gdown 1QkSY9W5RyaBnY8c5FLIsmpPVXoHTQ-fb"
      ],
      "metadata": {
        "id": "QJwZt1ZXmDW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zd2j75eJmNrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/sample_data/rag_eval_docs.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "23ADIw5anChW",
        "outputId": "e28e4f05-271e-4efc-a27e-eb26543a5f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                              title  \\\n",
              "0   1                   Machine Learning   \n",
              "1   2                      Deep Learning   \n",
              "2   3  Natural Language Processing (NLP)   \n",
              "3   4                           Pyramids   \n",
              "4   5                     Photosynthesis   \n",
              "5   6                            Biology   \n",
              "6   7                  Quantum Mechanics   \n",
              "7   8                     Cryptocurrency   \n",
              "8   9                   Renewable Energy   \n",
              "9  10            Artificial Intelligence   \n",
              "\n",
              "                                             context  \n",
              "0  Machine learning is a field of artificial inte...  \n",
              "1  Deep learning is a subset of machine learning ...  \n",
              "2  NLP is a branch of AI that enables computers t...  \n",
              "3  Pyramids are ancient structures, often serving...  \n",
              "4  Photosynthesis is the process plants use to co...  \n",
              "5  Biology is the study of living organisms, cove...  \n",
              "6  Quantum mechanics is a branch of physics that ...  \n",
              "7  Cryptocurrency is a digital currency that uses...  \n",
              "8  Renewable energy sources, such as solar and wi...  \n",
              "9  Artificial intelligence refers to machines mim...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7287336-4dc6-4a5f-846e-e4c9f61b8d3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Machine Learning</td>\n",
              "      <td>Machine learning is a field of artificial inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>Deep learning is a subset of machine learning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Natural Language Processing (NLP)</td>\n",
              "      <td>NLP is a branch of AI that enables computers t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Pyramids</td>\n",
              "      <td>Pyramids are ancient structures, often serving...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Photosynthesis</td>\n",
              "      <td>Photosynthesis is the process plants use to co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Biology</td>\n",
              "      <td>Biology is the study of living organisms, cove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Quantum Mechanics</td>\n",
              "      <td>Quantum mechanics is a branch of physics that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Cryptocurrency</td>\n",
              "      <td>Cryptocurrency is a digital currency that uses...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Renewable Energy</td>\n",
              "      <td>Renewable energy sources, such as solar and wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>Artificial intelligence refers to machines mim...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7287336-4dc6-4a5f-846e-e4c9f61b8d3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7287336-4dc6-4a5f-846e-e4c9f61b8d3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7287336-4dc6-4a5f-846e-e4c9f61b8d3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9ad7915c-cc84-4d73-ba3c-42dd5a416d46\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ad7915c-cc84-4d73-ba3c-42dd5a416d46')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9ad7915c-cc84-4d73-ba3c-42dd5a416d46 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_24e5b6a7-9b0c-4d6a-b07c-5f9fc9048bc6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_24e5b6a7-9b0c-4d6a-b07c-5f9fc9048bc6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Renewable Energy\",\n          \"Deep Learning\",\n          \"Biology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.\",\n          \"Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.\",\n          \"Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "orient\t   Structure               produced\tExample output\n",
        "'records'\tList of row dicts\t       [{'col1': val1, 'col2': val2}, ...]\n",
        "'dict'\t  Dict of columns\t         {'col1': [..], 'col2': [..]}\n",
        "'list'\t  Dict of columns as lists {'col1': [...], 'col2': [...]}\n",
        "'index'\t  Dict of index to dicts\t {0: {'col1': val1, ...}, 1: {...}}\n",
        "\n",
        "The orient parameter controls how the DataFrame is converted to a dictionary."
      ],
      "metadata": {
        "id": "Lws9VbLkob7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "docs = df.to_dict(orient='records')\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY6UFPKEnR_z",
        "outputId": "c1ae36f6-d537-4eb4-e1b0-28e465ee54d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 1,\n",
              "  'title': 'Machine Learning',\n",
              "  'context': 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.'},\n",
              " {'id': 2,\n",
              "  'title': 'Deep Learning',\n",
              "  'context': 'Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.'},\n",
              " {'id': 3,\n",
              "  'title': 'Natural Language Processing (NLP)',\n",
              "  'context': 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'},\n",
              " {'id': 4,\n",
              "  'title': 'Pyramids',\n",
              "  'context': 'Pyramids are ancient structures, often serving as tombs for pharaohs in Egypt. The Great Pyramid of Giza is one of the Seven Wonders of the Ancient World. Their construction remains a subject of fascination and speculation.'},\n",
              " {'id': 5,\n",
              "  'title': 'Photosynthesis',\n",
              "  'context': 'Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.'},\n",
              " {'id': 6,\n",
              "  'title': 'Biology',\n",
              "  'context': 'Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.'},\n",
              " {'id': 7,\n",
              "  'title': 'Quantum Mechanics',\n",
              "  'context': 'Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels. It challenges classical physics with concepts like wave-particle duality and uncertainty. Key figures include Einstein, SchrÃ¶dinger, and Heisenberg.'},\n",
              " {'id': 8,\n",
              "  'title': 'Cryptocurrency',\n",
              "  'context': 'Cryptocurrency is a digital currency that uses cryptography for secure transactions. Bitcoin, the first cryptocurrency, was launched in 2009. Its decentralized nature allows peer-to-peer transfers without traditional banks.'},\n",
              " {'id': 9,\n",
              "  'title': 'Renewable Energy',\n",
              "  'context': 'Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'},\n",
              " {'id': 10,\n",
              "  'title': 'Artificial Intelligence',\n",
              "  'context': \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to metadata(which is Langchain format to proceed with further processing)\n",
        "from langchain.docstore.document import Document\n",
        "precessed_docs = []\n",
        "\n",
        "for doc in docs:\n",
        "  metadata = {\n",
        "      \"title\": doc['title'],\n",
        "      \"id\": doc['id'],\n",
        "  }\n",
        "  data = doc['context']\n",
        "  precessed_docs.append(Document(page_content=data, metadata=metadata))"
      ],
      "metadata": {
        "id": "YQpopfkupbAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this whol process of csv -> dict -> metadata could be done by Langchain csv loader directly"
      ],
      "metadata": {
        "id": "-kXJ2fbwsCO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precessed_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSehyp1fr-nF",
        "outputId": "e8119475-6e5b-4034-bcf1-4929c6b8ef19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'title': 'Machine Learning', 'id': 1}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.'),\n",
              " Document(metadata={'title': 'Deep Learning', 'id': 2}, page_content='Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.'),\n",
              " Document(metadata={'title': 'Natural Language Processing (NLP)', 'id': 3}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n",
              " Document(metadata={'title': 'Pyramids', 'id': 4}, page_content='Pyramids are ancient structures, often serving as tombs for pharaohs in Egypt. The Great Pyramid of Giza is one of the Seven Wonders of the Ancient World. Their construction remains a subject of fascination and speculation.'),\n",
              " Document(metadata={'title': 'Photosynthesis', 'id': 5}, page_content='Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.'),\n",
              " Document(metadata={'title': 'Biology', 'id': 6}, page_content='Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.'),\n",
              " Document(metadata={'title': 'Quantum Mechanics', 'id': 7}, page_content='Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels. It challenges classical physics with concepts like wave-particle duality and uncertainty. Key figures include Einstein, SchrÃ¶dinger, and Heisenberg.'),\n",
              " Document(metadata={'title': 'Cryptocurrency', 'id': 8}, page_content='Cryptocurrency is a digital currency that uses cryptography for secure transactions. Bitcoin, the first cryptocurrency, was launched in 2009. Its decentralized nature allows peer-to-peer transfers without traditional banks.'),\n",
              " Document(metadata={'title': 'Renewable Energy', 'id': 9}, page_content='Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'),\n",
              " Document(metadata={'title': 'Artificial Intelligence', 'id': 10}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Index Document and Embedding in vector db"
      ],
      "metadata": {
        "id": "sGNOfxtIr84U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "chroma_db= Chroma.from_documents(documents=precessed_docs,embedding =embeddingmodel,collection_name='my_eval',collection_metadata={\"hnsw:space\":'cosine'},\n",
        "                                 persist_directory='/myevaldb')"
      ],
      "metadata": {
        "id": "yRNG70LdqYAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load from disc\n",
        "chroma_db =  Chroma(embedding_function =embeddingmodel,collection_name='my_eval',\n",
        "                                 persist_directory='/myevaldb')"
      ],
      "metadata": {
        "id": "RZi9ogvQ01aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chroma_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs6pvrZ_1baf",
        "outputId": "37b4c7b8-ab32-48af-d57c-b3a11cd0e1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7a2c13a35c40>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#semaintic similarity based retrieval"
      ],
      "metadata": {
        "id": "uoujqzRZ1hFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#score_threshold- if similarity score is less than score_threshold it wont be considered as relavant document, on top of this top N documents will be filtered based on k=N\n",
        "\n",
        "similarity_retriever= chroma_db.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={ \"score_threshold\" : 0.3 , \"k\" : 3}\n",
        "                                             )"
      ],
      "metadata": {
        "id": "iqwPbNRA1edX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just to view the retrieved documents in a good format\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def display_docs(docs):\n",
        "  for doc in docs:\n",
        "    print(\"Metadata :\", doc.metadata)\n",
        "    print(\"Content Brief:\")\n",
        "    display(Markdown(doc.page_content))\n",
        "    print()"
      ],
      "metadata": {
        "id": "fQNrTKhr5lQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query='what is AI'\n",
        "top_docs = similarity_retriever.invoke(query)\n",
        "display_docs(top_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "0hzEKr1V51kB",
        "outputId": "e7d39928-155a-45b8-d920-c537a6469960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata : {'id': 10, 'title': 'Artificial Intelligence'}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'title': 'Natural Language Processing (NLP)', 'id': 3}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'id': 1, 'title': 'Machine Learning'}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here only one doucment is retrieved though k=3 because only 1 doc in the database is related to photosynthesis"
      ],
      "metadata": {
        "id": "UTU5SkUs6KtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query='what is Photosynthesis'\n",
        "top_docs = similarity_retriever.invoke(query)\n",
        "display_docs(top_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "bVdHqVxF54xR",
        "outputId": "010d90c1-134f-4eed-bc6d-0eff3bc591cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata : {'id': 5, 'title': 'Photosynthesis'}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG pipeline"
      ],
      "metadata": {
        "id": "vjzD5uhf6Urq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
        "              Answer the following question using only the following pieces of retrieved context.\n",
        "              If the answer is not in the context, do not make up answers, just say that you don't know.\n",
        "              Keep the answer to the points based on the information from the context.\n",
        "\n",
        "              Question: {question}\n",
        "              Context: {context}\n",
        "\n",
        "              Answer:\n",
        "\n",
        "\n",
        "              \"\"\"\n",
        "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
      ],
      "metadata": {
        "id": "OXA485wW6SV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "similarity_retriever (Team 1) â†’ Fetches relevant docs.\n",
        "\n",
        "src_rag_response_chain (Team 2) â†’ Formats docs + prompts GPT + parses output.\n",
        "\n",
        "Each chain does its own job well.\n",
        "If you merged them into one huge function, debugging, replacing parts, or improving performance (like caching retrieval results) becomes messy.\n",
        "\n",
        "So having two stages = modularity + maintainability."
      ],
      "metadata": {
        "id": "CavTcaKQZx6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e9VJMgJ3RTuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "src_rag_response_chain = ({\n",
        "    \"context\":(itemgetter('context')\n",
        "    | RunnableLambda(format_docs)),\n",
        "               \"question\":itemgetter(\"question\")}\n",
        "               | rag_prompt_template\n",
        "               | chatgpt\n",
        "               | StrOutputParser() )\n",
        "\n",
        "rag_chain_w_sources = (\n",
        "    {\"context\": similarity_retriever, \"question\": RunnablePassthrough()}\n",
        "    | RunnablePassthrough.assign(\n",
        "        response=src_rag_response_chain,\n",
        "    )\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VNWCymgwRVDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how do plants survive?\"\n",
        "result = rag_chain_w_sources.invoke(query)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knx_pLs7aFnv",
        "outputId": "c9692b5b-8ef4-4aa3-e962-6ed34f37d4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': [Document(id='4783b169-b905-4d2b-b529-97ab6b54e897', metadata={'id': 5, 'title': 'Photosynthesis'}, page_content='Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.')],\n",
              " 'question': 'how do plants survive?',\n",
              " 'response': 'Plants survive by using a process called photosynthesis to convert sunlight into energy. This process produces glucose, which serves as food for the plant, and releases oxygen as a byproduct.'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Artificial Intelligence?\"\n",
        "result = rag_chain_w_sources.invoke(query)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDzTJU_naJzq",
        "outputId": "91ee33fe-05c7-4d17-bac4-2e9ad485b60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': [Document(id='4be2dad3-b269-49c0-9193-906e65d704da', metadata={'title': 'Artificial Intelligence', 'id': 10}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n",
              "  Document(id='155edbf1-acda-40fc-993a-eceb437cd68a', metadata={'title': 'Machine Learning', 'id': 1}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.'),\n",
              "  Document(id='a3a26008-cbe0-45a9-897b-962d39d3fb54', metadata={'title': 'Natural Language Processing (NLP)', 'id': 3}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.')],\n",
              " 'question': 'What is Artificial Intelligence?',\n",
              " 'response': \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation\n"
      ],
      "metadata": {
        "id": "7T6UivN8aZRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_context = [doc.page_content for doc in result['context']]\n",
        "retrieved_context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1nMSec8aNAo",
        "outputId": "4b300f25-47bc-4b01-d878-fd666b534dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n",
              " 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.',\n",
              " 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_answer = \"\"\"AI, also known as Artificial Intelligence is used to build complex systems for applications\n",
        "                like virtual assistants, robotics and autonomous vehicles.\"\"\""
      ],
      "metadata": {
        "id": "lKFqZ3Xnac1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just for us to understand experiment purpose\n",
        "new_context =[\"Machine Learning is the study of algorithm which learn with more data\",\n",
        "              \"AI is known as Artificial Intelligence \"] + retrieved_context"
      ],
      "metadata": {
        "id": "-hx7t1o4afua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation metrics"
      ],
      "metadata": {
        "id": "hK6b3v9gapo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import ContextualPrecisionMetric\n",
        "from deepeval import evaluate\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input = result['question'],\n",
        "    actual_output=result['response'],\n",
        "    expected_output=human_answer,\n",
        "    retrieval_context=retrieved_context\n",
        ")\n",
        "\n",
        "metrics = ContextualPrecisionMetric(\n",
        "    threshold=0.55,\n",
        "    model ='gpt-4o',\n",
        "    include_reason=True,\n",
        "    verbose_mode=True)\n",
        "\n",
        "result = evaluate([test_case], [metrics])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "-J6CnfTGamn9",
        "outputId": "c30f85a1-934d-4909-a3ab-afe73b5acad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'EvaluationResult' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4054599228.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m test_case = LLMTestCase(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mactual_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mexpected_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhuman_answer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'EvaluationResult' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import ContextualPrecisionMetric\n",
        "from deepeval import evaluate\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input = result['question'],\n",
        "    actual_output=result['response'],\n",
        "    expected_output=human_answer,\n",
        "    retrieval_context=new_context\n",
        ")\n",
        "\n",
        "metrics = ContextualPrecisionMetric(\n",
        "    threshold=0.55,\n",
        "    model ='gpt-4o',\n",
        "    include_reason=True,\n",
        "    verbose_mode=True)\n",
        "\n",
        "result = evaluate([test_case], [metrics])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6f07887e47d8427a952b3220c5932899",
            "b5104e53fac24a4b812153765f21527a"
          ]
        },
        "id": "i6GHBMS4amkT",
        "outputId": "59c740e9-1829-4a2e-92e4-9c2b0a255e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f07887e47d8427a952b3220c5932899"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepeval.evaluate.execute:in _a_execute_llm_test_cases\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Contextual Precision Verbose Logs\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Contextual Precision Verbose Logs\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The context 'Machine Learning is the study of algorithm which learn with more data' does not \n",
              "directly address the question about Artificial Intelligence or its applications.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": \"The context 'AI is known as Artificial Intelligence' directly defines AI, which is relevant to \n",
              "the input question.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": \"The context 'Artificial intelligence refers to machines mimicking human intelligence, like \n",
              "problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles.'\n",
              "directly addresses the question and matches the expected output.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The context 'Machine learning is a field of artificial intelligence focused on enabling systems \n",
              "to learn patterns from data.' focuses on machine learning rather than AI as a whole, and does not mention \n",
              "applications like virtual assistants or autonomous vehicles.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The context 'NLP is a branch of AI that enables computers to understand, interpret, and generate\n",
              "human language.' focuses on NLP, a specific branch of AI, and does not address the broader question about AI and \n",
              "its applications.\"\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 0.5833333333333333\n",
              "Reason: The score is 0.58 because the first node, ranked highest, contains the context 'Machine Learning is the \n",
              "study of algorithm which learn with more data', which does not directly address the question about Artificial \n",
              "Intelligence or its applications. This irrelevant node should be ranked lower. However, the second and third nodes \n",
              "provide relevant information, with the second node defining AI and the third node explaining its applications, \n",
              "which justifies the current score.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The context 'Machine Learning is the study of algorithm which learn with more data' does not \n",
              "directly address the question about Artificial Intelligence or its applications.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": \"The context 'AI is known as Artificial Intelligence' directly defines AI, which is relevant to \n",
              "the input question.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": \"The context 'Artificial intelligence refers to machines mimicking human intelligence, like \n",
              "problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles.'\n",
              "directly addresses the question and matches the expected output.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The context 'Machine learning is a field of artificial intelligence focused on enabling systems \n",
              "to learn patterns from data.' focuses on machine learning rather than AI as a whole, and does not mention \n",
              "applications like virtual assistants or autonomous vehicles.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The context 'NLP is a branch of AI that enables computers to understand, interpret, and generate\n",
              "human language.' focuses on NLP, a specific branch of AI, and does not address the broader question about AI and \n",
              "its applications.\"\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 0.5833333333333333\n",
              "Reason: The score is 0.58 because the first node, ranked highest, contains the context 'Machine Learning is the \n",
              "study of algorithm which learn with more data', which does not directly address the question about Artificial \n",
              "Intelligence or its applications. This irrelevant node should be ranked lower. However, the second and third nodes \n",
              "provide relevant information, with the second node defining AI and the third node explaining its applications, \n",
              "which justifies the current score.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Contextual Precision (score: 0.5833333333333333, threshold: 0.55, strict: False, evaluation model: gpt-4o, reason: The score is 0.58 because the first node, ranked highest, contains the context 'Machine Learning is the study of algorithm which learn with more data', which does not directly address the question about Artificial Intelligence or its applications. This irrelevant node should be ranked lower. However, the second and third nodes provide relevant information, with the second node defining AI and the third node explaining its applications, which justifies the current score., error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What is Artificial Intelligence?\n",
            "  - actual output: Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\n",
            "  - expected output: AI, also known as Artificial Intelligence is used to build complex systems for applications\n",
            "                like virtual assistants, robotics and autonomous vehicles.\n",
            "  - context: None\n",
            "  - retrieval context: ['Machine Learning is the study of algorithm which learn with more data', 'AI is known as Artificial Intelligence ', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Contextual Precision: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
              "Â» \u001b]8;id=786466;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
              "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m7.\u001b[0m54s | token cost: \u001b[1;36m0.006502500000000001\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   Â» Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.</span>54s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.006502500000000001</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Success:\", result.test_results[0].metrics_data[0].success)\n",
        "print(\"Score:\", result.test_results[0].metrics_data[0].score)\n",
        "print(\"Reason:\", result.test_results[0].metrics_data[0].reason)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5tfU0w2amhu",
        "outputId": "a3802111-729e-488c-df3a-2986a646e2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: True\n",
            "Score: 0.5833333333333333\n",
            "Reason: The score is 0.58 because the first node, ranked highest, contains the context 'Machine Learning is the study of algorithm which learn with more data', which does not directly address the question about Artificial Intelligence or its applications. This irrelevant node should be ranked lower. However, the second and third nodes provide relevant information, with the second node defining AI and the third node explaining its applications, which justifies the current score.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_context1 =[\"NVIDIA makes chips for AI\",\n",
        "              \"AI is known as Artificial Intelligence \",\n",
        "              \"Physics and Maths are simple\",\n",
        "              \"Chemistry is really simple if you know the fundamentals\"] + retrieved_context"
      ],
      "metadata": {
        "id": "Vtbn54tqamfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_answer = \"\"\"AI, also known as Artificial Intelligence is used to build complex systems for applications\n",
        "                like virtual assistants, robotics and autonomous vehicles.\"\"\""
      ],
      "metadata": {
        "id": "ZgxENFanamS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import ContextualRecallMetric\n",
        "from deepeval import evaluate\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input = result['question'],\n",
        "    actual_output=result['response'],\n",
        "    expected_output=human_answer,\n",
        "    retrieval_context=new_context1\n",
        ")\n",
        "\n",
        "metrics = ContextualRecallMetric(\n",
        "    threshold=0.55,\n",
        "    model ='gpt-4o',\n",
        "    include_reason=True,\n",
        "    verbose_mode=True)\n",
        "\n",
        "result = evaluate([test_case], [metrics])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "19eac8f4b4f04b63831af70a341ea7a2",
            "50aa3aadbc6542baaf36c4e6a8ba5292"
          ]
        },
        "id": "MLTtky5TamEY",
        "outputId": "65bc31c1-53c5-4054-aa85-52b38b32d38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19eac8f4b4f04b63831af70a341ea7a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepeval.evaluate.execute:in _a_execute_llm_test_cases\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Contextual Recall Verbose Logs\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Contextual Recall Verbose Logs\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": \"The sentence can be attributed to the 2nd and 5th nodes. The 2nd node states 'AI is known as \n",
              "Artificial Intelligence', and the 5th node mentions 'AI includes applications like virtual assistants, robotics, \n",
              "and autonomous vehicles...'.\"\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 1.0\n",
              "Reason: The score is 1.00 because every sentence in the expected output is perfectly aligned with the nodes in the \n",
              "retrieval context, specifically the 2nd and 5th nodes, which provide comprehensive support for the information \n",
              "presented.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": \"The sentence can be attributed to the 2nd and 5th nodes. The 2nd node states 'AI is known as \n",
              "Artificial Intelligence', and the 5th node mentions 'AI includes applications like virtual assistants, robotics, \n",
              "and autonomous vehicles...'.\"\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 1.0\n",
              "Reason: The score is 1.00 because every sentence in the expected output is perfectly aligned with the nodes in the \n",
              "retrieval context, specifically the 2nd and 5th nodes, which provide comprehensive support for the information \n",
              "presented.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Contextual Recall (score: 1.0, threshold: 0.55, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because every sentence in the expected output is perfectly aligned with the nodes in the retrieval context, specifically the 2nd and 5th nodes, which provide comprehensive support for the information presented., error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What is Artificial Intelligence?\n",
            "  - actual output: Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\n",
            "  - expected output: AI, also known as Artificial Intelligence is used to build complex systems for applications\n",
            "                like virtual assistants, robotics and autonomous vehicles.\n",
            "  - context: None\n",
            "  - retrieval context: ['NVIDIA makes chips for AI', 'AI is known as Artificial Intelligence ', 'Physics and Maths are simple', 'Chemistry is really simple if you know the fundamentals', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Contextual Recall: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
              "Â» \u001b]8;id=31719;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
              "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m3.\u001b[0m88s | token cost: \u001b[1;36m0.0037450000000000005\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   Â» Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.</span>88s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0037450000000000005</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in above case (recall) we are getting 100 percent accuracy even though there are bit non relevant documents because false negative is 0. and formula is TP/(FN+TP)"
      ],
      "metadata": {
        "id": "dil3aAQOdgsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import ContextualRelevancyMetric\n",
        "from deepeval import evaluate\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input = result['question'],\n",
        "    actual_output=result['response'],\n",
        "    expected_output=human_answer,\n",
        "    retrieval_context=new_context\n",
        ")\n",
        "\n",
        "metrics = ContextualRelevancyMetric(\n",
        "    threshold=0.55,\n",
        "    model ='gpt-4o',\n",
        "    include_reason=True,\n",
        "    verbose_mode=True)\n",
        "\n",
        "result = evaluate([test_case], [metrics])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7dc0f3e64b864ffbaef08bc782c6a367",
            "ab6f0cfeeeb9452fa6e654a1aa3566a1"
          ]
        },
        "id": "FVXg58Ofd1an",
        "outputId": "78cf675c-91b5-4c5d-d4bc-6b6456e5a40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dc0f3e64b864ffbaef08bc782c6a367"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepeval.evaluate.execute:in _a_execute_llm_test_cases\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Contextual Relevancy Verbose Logs\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Contextual Relevancy Verbose Logs\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"NVIDIA makes chips for AI\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"AI is known as Artificial Intelligence\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"Physics and Maths are simple\",\n",
              "                \"verdict\": \"no\",\n",
              "                \"reason\": \"The statement 'Physics and Maths are simple' does not relate to the input question 'What\n",
              "is Artificial Intelligence?' as it discusses unrelated subjects.\"\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"Chemistry is really simple if you know the fundamentals\",\n",
              "                \"verdict\": \"no\",\n",
              "                \"reason\": \"The statement 'Chemistry is really simple if you know the fundamentals' is unrelated to \n",
              "the topic of Artificial Intelligence.\"\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"Artificial intelligence refers to machines mimicking human intelligence, like \n",
              "problem-solving and learning.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"AI includes applications like virtual assistants, robotics, and autonomous \n",
              "vehicles.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"It's evolving rapidly with advancements in machine learning and deep learning.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"Machine learning is a field of artificial intelligence focused on enabling systems to\n",
              "learn patterns from data.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"Algorithms analyze past data to make predictions or classify information.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"Popular applications include recommendation systems and image recognition.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"NLP is a branch of AI that enables computers to understand, interpret, and generate \n",
              "human language.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"Techniques include tokenization, stemming, and sentiment analysis.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"Applications range from chatbots to language translation services.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 0.8461538461538461\n",
              "Reason: The score is 0.85 because while the retrieval context contains several relevant statements about AI, such \n",
              "as 'Artificial intelligence refers to machines mimicking human intelligence' and 'AI includes applications like \n",
              "virtual assistants, robotics, and autonomous vehicles,' it also includes unrelated content like 'Physics and Maths \n",
              "are simple,' which detracts from the overall relevancy.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"NVIDIA makes chips for AI\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"AI is known as Artificial Intelligence\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"Physics and Maths are simple\",\n",
              "                \"verdict\": \"no\",\n",
              "                \"reason\": \"The statement 'Physics and Maths are simple' does not relate to the input question 'What\n",
              "is Artificial Intelligence?' as it discusses unrelated subjects.\"\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"Chemistry is really simple if you know the fundamentals\",\n",
              "                \"verdict\": \"no\",\n",
              "                \"reason\": \"The statement 'Chemistry is really simple if you know the fundamentals' is unrelated to \n",
              "the topic of Artificial Intelligence.\"\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"Artificial intelligence refers to machines mimicking human intelligence, like \n",
              "problem-solving and learning.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"AI includes applications like virtual assistants, robotics, and autonomous \n",
              "vehicles.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"It's evolving rapidly with advancements in machine learning and deep learning.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"Machine learning is a field of artificial intelligence focused on enabling systems to\n",
              "learn patterns from data.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"Algorithms analyze past data to make predictions or classify information.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"Popular applications include recommendation systems and image recognition.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    },\n",
              "    {\n",
              "        \"verdicts\": [\n",
              "            {\n",
              "                \"statement\": \"NLP is a branch of AI that enables computers to understand, interpret, and generate \n",
              "human language.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"Techniques include tokenization, stemming, and sentiment analysis.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            },\n",
              "            {\n",
              "                \"statement\": \"Applications range from chatbots to language translation services.\",\n",
              "                \"verdict\": \"yes\",\n",
              "                \"reason\": null\n",
              "            }\n",
              "        ]\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 0.8461538461538461\n",
              "Reason: The score is 0.85 because while the retrieval context contains several relevant statements about AI, such \n",
              "as 'Artificial intelligence refers to machines mimicking human intelligence' and 'AI includes applications like \n",
              "virtual assistants, robotics, and autonomous vehicles,' it also includes unrelated content like 'Physics and Maths \n",
              "are simple,' which detracts from the overall relevancy.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Contextual Relevancy (score: 0.8461538461538461, threshold: 0.55, strict: False, evaluation model: gpt-4o, reason: The score is 0.85 because while the retrieval context contains several relevant statements about AI, such as 'Artificial intelligence refers to machines mimicking human intelligence' and 'AI includes applications like virtual assistants, robotics, and autonomous vehicles,' it also includes unrelated content like 'Physics and Maths are simple,' which detracts from the overall relevancy., error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What is Artificial Intelligence?\n",
            "  - actual output: Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\n",
            "  - expected output: AI, also known as Artificial Intelligence is used to build complex systems for applications\n",
            "                like virtual assistants, robotics and autonomous vehicles.\n",
            "  - context: None\n",
            "  - retrieval context: ['NVIDIA makes chips for AI', 'AI is known as Artificial Intelligence ', 'Physics and Maths are simple', 'Chemistry is really simple if you know the fundamentals', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Contextual Relevancy: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
              "Â» \u001b]8;id=944448;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
              "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m4.\u001b[0m17s | token cost: \u001b[1;36m0.015230000000000002\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   Â» Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.</span>17s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.015230000000000002</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator metrics\n",
        "since its the chcekpoint in generation part of rag pipeline in test case no need to give context similar to retrieval metrics"
      ],
      "metadata": {
        "id": "QMpPVXl8ggz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import AnswerRelevancyMetric\n",
        "from deepeval import evaluate\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input = result['question'],\n",
        "    actual_output=result['response'],\n",
        ")\n",
        "\n",
        "metrics = AnswerRelevancyMetric(\n",
        "    threshold=0.55,\n",
        "    model ='gpt-4o',\n",
        "    include_reason=True,\n",
        "    verbose_mode=True)\n",
        "\n",
        "result = evaluate([test_case], [metrics])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bfd11a9c03ed41b5b018936d6d4c3005",
            "2d95c9c5b0b6453a8c54c9a7c8f9c36f"
          ]
        },
        "id": "8S9M9VLxgZgY",
        "outputId": "aa4050e6-e5e6-4d4a-8c6b-490ff9c01b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfd11a9c03ed41b5b018936d6d4c3005"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepeval.evaluate.execute:in _a_execute_llm_test_cases\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Answer Relevancy Verbose Logs\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer Relevancy Verbose Logs\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Statements:\n",
              "[\n",
              "    \"Artificial intelligence refers to machines mimicking human intelligence.\",\n",
              "    \"AI includes applications like virtual assistants, robotics, and autonomous vehicles.\",\n",
              "    \"AI is evolving rapidly with advancements in machine learning and deep learning.\"\n",
              "] \n",
              " \n",
              "Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 1.0\n",
              "Reason: The score is 1.00 because the response perfectly addresses the question about Artificial Intelligence \n",
              "without any irrelevant information. Great job!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Statements:\n",
              "[\n",
              "    \"Artificial intelligence refers to machines mimicking human intelligence.\",\n",
              "    \"AI includes applications like virtual assistants, robotics, and autonomous vehicles.\",\n",
              "    \"AI is evolving rapidly with advancements in machine learning and deep learning.\"\n",
              "] \n",
              " \n",
              "Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 1.0\n",
              "Reason: The score is 1.00 because the response perfectly addresses the question about Artificial Intelligence \n",
              "without any irrelevant information. Great job!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Answer Relevancy (score: 1.0, threshold: 0.55, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response perfectly addresses the question about Artificial Intelligence without any irrelevant information. Great job!, error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What is Artificial Intelligence?\n",
            "  - actual output: Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\n",
            "  - expected output: None\n",
            "  - context: None\n",
            "  - retrieval context: None\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Answer Relevancy: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
              "Â» \u001b]8;id=91555;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
              "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m4.\u001b[0m21s | token cost: \u001b[1;36m0.0039025\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   Â» Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.</span>21s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0039025</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import FaithfulnessMetric, HallucinationMetric, GEval\n",
        "from deepeval import evaluate\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input = result['question'],\n",
        "    actual_output=result['response'],\n",
        "    retrieval_context=new_context\n",
        ")\n",
        "\n",
        "metrics = FaithfulnessMetric(\n",
        "    threshold=0.55,\n",
        "    model ='gpt-4o',\n",
        "    include_reason=True,\n",
        "    verbose_mode=True)\n",
        "\n",
        "result = evaluate([test_case], [metrics])"
      ],
      "metadata": {
        "id": "oqiRypFnOr5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "492d8ed0e87841528f0a20c2d564c2e9",
            "606b44265e5f42298c63245f0b5d43b9"
          ]
        },
        "outputId": "e46fbcdf-e022-49cb-8ccd-bdacb87cd107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "492d8ed0e87841528f0a20c2d564c2e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepeval.evaluate.execute:in _a_execute_llm_test_cases\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Faithfulness Verbose Logs\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Faithfulness Verbose Logs\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truths (limit=None):\n",
              "[\n",
              "    \"Machine Learning is the study of algorithms that learn with more data.\",\n",
              "    \"AI is known as Artificial Intelligence.\",\n",
              "    \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning.\",\n",
              "    \"AI includes applications like virtual assistants, robotics, and autonomous vehicles.\",\n",
              "    \"AI is evolving rapidly with advancements in machine learning and deep learning.\",\n",
              "    \"Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from \n",
              "data.\",\n",
              "    \"Machine learning algorithms analyze past data to make predictions or classify information.\",\n",
              "    \"Popular applications of machine learning include recommendation systems and image recognition.\",\n",
              "    \"NLP is a branch of AI that enables computers to understand, interpret, and generate human language.\",\n",
              "    \"NLP techniques include tokenization, stemming, and sentiment analysis.\",\n",
              "    \"NLP applications range from chatbots to language translation services.\"\n",
              "] \n",
              " \n",
              "Claims:\n",
              "[\n",
              "    \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning.\",\n",
              "    \"AI includes applications like virtual assistants, robotics, and autonomous vehicles.\",\n",
              "    \"AI is evolving rapidly with advancements in machine learning and deep learning.\"\n",
              "] \n",
              " \n",
              "Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 1.0\n",
              "Reason: The score is 1.00 because there are no contradictions between the actual output and the retrieval context. \n",
              "Everything aligns perfectly, showcasing a high level of accuracy and consistency. Keep up the great work!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Truths (limit=None):\n",
              "[\n",
              "    \"Machine Learning is the study of algorithms that learn with more data.\",\n",
              "    \"AI is known as Artificial Intelligence.\",\n",
              "    \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning.\",\n",
              "    \"AI includes applications like virtual assistants, robotics, and autonomous vehicles.\",\n",
              "    \"AI is evolving rapidly with advancements in machine learning and deep learning.\",\n",
              "    \"Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from \n",
              "data.\",\n",
              "    \"Machine learning algorithms analyze past data to make predictions or classify information.\",\n",
              "    \"Popular applications of machine learning include recommendation systems and image recognition.\",\n",
              "    \"NLP is a branch of AI that enables computers to understand, interpret, and generate human language.\",\n",
              "    \"NLP techniques include tokenization, stemming, and sentiment analysis.\",\n",
              "    \"NLP applications range from chatbots to language translation services.\"\n",
              "] \n",
              " \n",
              "Claims:\n",
              "[\n",
              "    \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning.\",\n",
              "    \"AI includes applications like virtual assistants, robotics, and autonomous vehicles.\",\n",
              "    \"AI is evolving rapidly with advancements in machine learning and deep learning.\"\n",
              "] \n",
              " \n",
              "Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": null\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 1.0\n",
              "Reason: The score is 1.00 because there are no contradictions between the actual output and the retrieval context. \n",
              "Everything aligns perfectly, showcasing a high level of accuracy and consistency. Keep up the great work!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Faithfulness (score: 1.0, threshold: 0.55, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions between the actual output and the retrieval context. Everything aligns perfectly, showcasing a high level of accuracy and consistency. Keep up the great work!, error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What is Artificial Intelligence?\n",
            "  - actual output: Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\n",
            "  - expected output: None\n",
            "  - context: None\n",
            "  - retrieval context: ['Machine Learning is the study of algorithm which learn with more data', 'AI is known as Artificial Intelligence ', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Faithfulness: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
              "Â» \u001b]8;id=303794;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
              "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m6.\u001b[0m03s | token cost: \u001b[1;36m0.0073075000000000015\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   Â» Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>03s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0073075000000000015</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import FaithfulnessMetric, HallucinationMetric, GEval\n",
        "from deepeval import evaluate\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input = result['question'],\n",
        "    actual_output=result['response'],\n",
        "    context=new_context1\n",
        ")\n",
        "\n",
        "metrics = HallucinationMetric(\n",
        "    threshold=0.55,\n",
        "    model ='gpt-4o',\n",
        "    include_reason=True,\n",
        "    verbose_mode=True)\n",
        "\n",
        "result = evaluate([test_case], [metrics])"
      ],
      "metadata": {
        "id": "pdmWm09lO3TE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3bc76345f1b47d597d5399faeeb2246",
            "4b2c369eac0c4361be7f3dca1ae5d471"
          ]
        },
        "outputId": "da803176-65bd-4c25-f4a3-01325b65e0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mHallucination Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Hallucination Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3bc76345f1b47d597d5399faeeb2246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepeval.evaluate.execute:in _a_execute_llm_test_cases\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Hallucination Verbose Logs\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hallucination Verbose Logs\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "**************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not mention NVIDIA or its role in making chips for AI.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not explicitly define AI as Artificial Intelligence.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not address the simplicity of Physics and Maths.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not discuss the simplicity of Chemistry.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": \"The actual output agrees with the context, describing AI as machines mimicking human \n",
              "intelligence and listing similar applications.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not specifically focus on machine learning or its applications like \n",
              "recommendation systems and image recognition.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not mention NLP or its techniques and applications.\"\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 0.8571428571428571\n",
              "Reason: The score is 0.86 because the actual output aligns with the context in describing AI broadly but fails to \n",
              "address several specific details and topics mentioned in the context, such as NVIDIA's role, explicit definitions, \n",
              "and specific AI applications like machine learning and NLP.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Verdicts:\n",
              "[\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not mention NVIDIA or its role in making chips for AI.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not explicitly define AI as Artificial Intelligence.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not address the simplicity of Physics and Maths.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not discuss the simplicity of Chemistry.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"yes\",\n",
              "        \"reason\": \"The actual output agrees with the context, describing AI as machines mimicking human \n",
              "intelligence and listing similar applications.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not specifically focus on machine learning or its applications like \n",
              "recommendation systems and image recognition.\"\n",
              "    },\n",
              "    {\n",
              "        \"verdict\": \"no\",\n",
              "        \"reason\": \"The actual output does not mention NLP or its techniques and applications.\"\n",
              "    }\n",
              "]\n",
              " \n",
              "Score: 0.8571428571428571\n",
              "Reason: The score is 0.86 because the actual output aligns with the context in describing AI broadly but fails to \n",
              "address several specific details and topics mentioned in the context, such as NVIDIA's role, explicit definitions, \n",
              "and specific AI applications like machine learning and NLP.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âŒ Hallucination (score: 0.8571428571428571, threshold: 0.55, strict: False, evaluation model: gpt-4o, reason: The score is 0.86 because the actual output aligns with the context in describing AI broadly but fails to address several specific details and topics mentioned in the context, such as NVIDIA's role, explicit definitions, and specific AI applications like machine learning and NLP., error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What is Artificial Intelligence?\n",
            "  - actual output: Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\n",
            "  - expected output: None\n",
            "  - context: ['NVIDIA makes chips for AI', 'AI is known as Artificial Intelligence ', 'Physics and Maths are simple', 'Chemistry is really simple if you know the fundamentals', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
            "  - retrieval context: None\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Hallucination: 0.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
              "Â» \u001b]8;id=527222;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
              "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m6.\u001b[0m75s | token cost: \u001b[1;36m0.0047550000000000005\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   Â» Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>75s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0047550000000000005</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "no verbose mode/no reason paramter allowed in Geval\n",
        "\n",
        "Geval customized evaluation metrix (checks quality)\n",
        "\n",
        "It mainly depends on these 5 criterias:\n",
        "\n",
        "Relevance -\tAlignment with user question\t(Semantic similarity, cosine distance, attention alignment)\n",
        "Coherence\t-Logical flow between sentences\t(Discourse modeling, attention dependency, perplexity)\n",
        "Conciseness\t-Minimal but sufficient length\t(Information density, MDL principle)\n",
        "Fluency -\tGrammatical and natural phrasing\t(LM probability, syntax modeling)\n",
        "Helpfulness\t-Practical usefulness of response\t(RLHF reward models, utility optimization)\n"
      ],
      "metadata": {
        "id": "_QdAHJND7mh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
        "from deepeval.metrics import GEval\n",
        "from deepeval import evaluate\n",
        "\n",
        "# Define your test case\n",
        "test_case = LLMTestCase(\n",
        "    input=result['question'],\n",
        "    actual_output=result['response'],\n",
        "    context=new_context1\n",
        ")\n",
        "\n",
        "# Define GEval metric for relevance\n",
        "geval_metric = GEval(\n",
        "    name=\"Relevance Evaluation\",\n",
        "    criteria=\"The response should be relevant to the input question and information provided in the context.\",\n",
        "    evaluation_params=[\n",
        "        LLMTestCaseParams.INPUT,\n",
        "        LLMTestCaseParams.CONTEXT\n",
        "    ],\n",
        "    threshold=0.6,\n",
        "    model=\"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "# Run the evaluation\n",
        "result = evaluate([test_case], [geval_metric])\n",
        "\n",
        "# Print results\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812,
          "referenced_widgets": [
            "9faa3b5924664d6f92d5b810521bff22",
            "e48c59d320cc4f65b9d86bfb3e552b25"
          ]
        },
        "id": "TQQPw5eMz2yN",
        "outputId": "109a9b94-360a-4ef2-d701-ea12ec1c02ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mRelevance Evaluation \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
              "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Relevance Evaluation </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
              "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9faa3b5924664d6f92d5b810521bff22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepeval.evaluate.execute:in _a_execute_llm_test_cases\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Relevance Evaluation [GEval] (score: 0.9851952800088839, threshold: 0.6, strict: False, evaluation model: gpt-4o-mini, reason: The response directly addresses the question about Artificial Intelligence by providing a clear definition and relevant examples, such as virtual assistants and robotics. It effectively utilizes the context information, particularly the definition provided, and elaborates on the applications and advancements in AI, demonstrating a strong alignment with the evaluation steps., error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What is Artificial Intelligence?\n",
            "  - actual output: Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\n",
            "  - expected output: None\n",
            "  - context: ['NVIDIA makes chips for AI', 'AI is known as Artificial Intelligence ', 'Physics and Maths are simple', 'Chemistry is really simple if you know the fundamentals', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
            "  - retrieval context: None\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Relevance Evaluation [GEval]: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
              "Â» \u001b]8;id=358876;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
              "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m5.\u001b[0m5s | token cost: \u001b[1;36m0.00018314999999999998\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   Â» Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.</span>5s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00018314999999999998</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "Â» Want to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
              "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Relevance Evaluation [GEval]', threshold=0.6, success=True, score=0.9851952800088839, reason='The response directly addresses the question about Artificial Intelligence by providing a clear definition and relevant examples, such as virtual assistants and robotics. It effectively utilizes the context information, particularly the definition provided, and elaborates on the applications and advancements in AI, demonstrating a strong alignment with the evaluation steps.', strict_mode=False, evaluation_model='gpt-4o-mini', error=None, evaluation_cost=0.00018314999999999998, verbose_logs='Criteria:\\nThe response should be relevant to the input question and information provided in the context. \\n \\nEvaluation Steps:\\n[\\n    \"Identify the main question or request in the input to establish the primary focus.\",\\n    \"Review the context provided to extract relevant information that supports or relates to the input.\",\\n    \"Assess the response to determine if it directly addresses the input question using the context information.\",\\n    \"Check for any discrepancies or irrelevant information in the response that does not align with the input or context.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 0.9851952800088839')], conversational=False, multimodal=False, input='What is Artificial Intelligence?', actual_output=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", expected_output=None, context=['NVIDIA makes chips for AI', 'AI is known as Artificial Intelligence ', 'Physics and Maths are simple', 'Chemistry is really simple if you know the fundamentals', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'], retrieval_context=None, turns=None, additional_metadata=None)] confident_link=None test_run_id=None\n"
          ]
        }
      ]
    }
  ]
}